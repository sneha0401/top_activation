{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CIFAR10.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"iYAvgeVDRXYG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610776607874,"user_tz":-330,"elapsed":56065,"user":{"displayName":"Dr Shiv Ram Dubey","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjtd_B-VgS3jkucANDIMEI21-5JajxJBYL4BagKOA=s64","userId":"14553895138990175535"}},"outputId":"e9f6fe8e-e785-4608-b61d-068268fafd41"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LLyFOsSoByip","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610776609043,"user_tz":-330,"elapsed":57225,"user":{"displayName":"Dr Shiv Ram Dubey","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjtd_B-VgS3jkucANDIMEI21-5JajxJBYL4BagKOA=s64","userId":"14553895138990175535"}},"outputId":"f74b2a53-50e0-4b6c-ea4a-fd6437f74ff8"},"source":["cd '/content/gdrive/My Drive/Colab Notebooks/Activation_Functions/CIFAR10/'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Colab Notebooks/Activation_Functions/CIFAR10\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"v_fG538P6N4l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610776609046,"user_tz":-330,"elapsed":57223,"user":{"displayName":"Dr Shiv Ram Dubey","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjtd_B-VgS3jkucANDIMEI21-5JajxJBYL4BagKOA=s64","userId":"14553895138990175535"}},"outputId":"611e90e1-43fb-4164-8161-168a719c8ab2"},"source":["!nvidia-smi"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Sat Jan 16 05:56:47 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   52C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MY9oaZ5cQt9D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610783189564,"user_tz":-330,"elapsed":6637736,"user":{"displayName":"Dr Shiv Ram Dubey","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjtd_B-VgS3jkucANDIMEI21-5JajxJBYL4BagKOA=s64","userId":"14553895138990175535"}},"outputId":"d7db7355-1f92-4bb5-dde9-39b1aaa41edb"},"source":["!python3 main_cifar10.py\n","#!python3 main_cifar10.py --resume --lr=0.001\n","#!python3 main_cifar10.py --resume --lr=0.0001"],"execution_count":4,"outputs":[{"output_type":"stream","text":["==> Preparing data..\n","Files already downloaded and verified\n","Files already downloaded and verified\n","==> Building model..\n","==> Resuming from checkpoint..\n","/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","\n","Epoch: 67\n"," [================================================================>]  Step: 2s810ms | Tot: 3m2s | Loss: 0.052 | Acc: 98.146% (49073/50000) 391/391 \n"," [================================================================>]  Step: 365ms | Tot: 11s468ms | Loss: 2.749 | Acc: 64.570% (6457/10000) 79/79 \n","\n","Epoch: 68\n"," [================================================================>]  Step: 300ms | Tot: 3m4s | Loss: 0.051 | Acc: 98.172% (49086/50000) 391/391 \n"," [================================================================>]  Step: 25ms | Tot: 11s148ms | Loss: 1.769 | Acc: 74.400% (7440/10000) 79/79 \n","\n","Epoch: 69\n"," [================================================================>]  Step: 296ms | Tot: 3m4s | Loss: 0.051 | Acc: 98.162% (49081/50000) 391/391 \n"," [================================================================>]  Step: 25ms | Tot: 11s114ms | Loss: 1.156 | Acc: 81.490% (8149/10000) 79/79 \n","Saving..\n","\n","Epoch: 70\n"," [================================================================>]  Step: 296ms | Tot: 3m4s | Loss: 0.045 | Acc: 98.398% (49199/50000) 391/391 \n"," [================================================================>]  Step: 25ms | Tot: 11s221ms | Loss: 1.780 | Acc: 76.250% (7625/10000) 79/79 \n","\n","Epoch: 71\n"," [================================================================>]  Step: 298ms | Tot: 3m4s | Loss: 0.045 | Acc: 98.396% (49198/50000) 391/391 \n"," [================================================================>]  Step: 24ms | Tot: 11s128ms | Loss: 0.813 | Acc: 83.720% (8372/10000) 79/79 \n","Saving..\n","\n","Epoch: 72\n"," [================================================================>]  Step: 296ms | Tot: 3m4s | Loss: 0.050 | Acc: 98.234% (49117/50000) 391/391 \n"," [================================================================>]  Step: 25ms | Tot: 11s139ms | Loss: 4.129 | Acc: 54.940% (5494/10000) 79/79 \n","\n","Epoch: 73\n"," [================================================================>]  Step: 298ms | Tot: 3m4s | Loss: 0.045 | Acc: 98.394% (49197/50000) 391/391 \n"," [================================================================>]  Step: 23ms | Tot: 11s144ms | Loss: 1.179 | Acc: 81.610% (8161/10000) 79/79 \n","\n","Epoch: 74\n"," [================================================================>]  Step: 302ms | Tot: 3m4s | Loss: 0.041 | Acc: 98.558% (49279/50000) 391/391 \n"," [================================================================>]  Step: 25ms | Tot: 11s162ms | Loss: 1.265 | Acc: 78.260% (7826/10000) 79/79 \n","\n","Epoch: 75\n"," [================================================================>]  Step: 297ms | Tot: 3m4s | Loss: 0.046 | Acc: 98.384% (49192/50000) 391/391 \n"," [================================================================>]  Step: 24ms | Tot: 11s140ms | Loss: 1.212 | Acc: 80.390% (8039/10000) 79/79 \n","\n","Epoch: 76\n"," [================================================================>]  Step: 295ms | Tot: 3m3s | Loss: 0.041 | Acc: 98.514% (49257/50000) 391/391 \n"," [================================================================>]  Step: 24ms | Tot: 11s200ms | Loss: 0.990 | Acc: 83.240% (8324/10000) 79/79 \n","\n","Epoch: 77\n"," [================================================================>]  Step: 296ms | Tot: 3m4s | Loss: 0.041 | Acc: 98.568% (49284/50000) 391/391 \n"," [================================================================>]  Step: 24ms | Tot: 11s185ms | Loss: 1.356 | Acc: 78.550% (7855/10000) 79/79 \n","\n","Epoch: 78\n"," [================================================================>]  Step: 296ms | Tot: 3m4s | Loss: 0.041 | Acc: 98.532% (49266/50000) 391/391 \n"," [================================================================>]  Step: 24ms | Tot: 11s99ms | Loss: 0.809 | Acc: 85.440% (8544/10000) 79/79 \n","Saving..\n","\n","Epoch: 79\n"," [================================================================>]  Step: 294ms | Tot: 3m4s | Loss: 0.044 | Acc: 98.440% (49220/50000) 391/391 \n"," [================================================================>]  Step: 24ms | Tot: 11s155ms | Loss: 1.415 | Acc: 80.270% (8027/10000) 79/79 \n","\n","Epoch: 80\n"," [================================================================>]  Step: 296ms | Tot: 3m4s | Loss: 0.042 | Acc: 98.534% (49267/50000) 391/391 \n"," [================================================================>]  Step: 23ms | Tot: 11s102ms | Loss: 1.008 | Acc: 83.310% (8331/10000) 79/79 \n","\n","Epoch: 81\n"," [================================================================>]  Step: 294ms | Tot: 3m4s | Loss: 0.037 | Acc: 98.686% (49343/50000) 391/391 \n"," [================================================================>]  Step: 24ms | Tot: 11s87ms | Loss: 1.093 | Acc: 83.180% (8318/10000) 79/79 \n","\n","Epoch: 82\n"," [================================================================>]  Step: 296ms | Tot: 3m4s | Loss: 0.038 | Acc: 98.622% (49311/50000) 391/391 \n"," [================================================================>]  Step: 25ms | Tot: 11s203ms | Loss: 3.244 | Acc: 64.180% (6418/10000) 79/79 \n","\n","Epoch: 83\n"," [================================================================>]  Step: 296ms | Tot: 3m4s | Loss: 0.038 | Acc: 98.684% (49342/50000) 391/391 \n"," [================================================================>]  Step: 25ms | Tot: 11s99ms | Loss: 1.144 | Acc: 81.290% (8129/10000) 79/79 \n","\n","Epoch: 84\n"," [================================================================>]  Step: 296ms | Tot: 3m4s | Loss: 0.036 | Acc: 98.688% (49344/50000) 391/391 \n"," [================================================================>]  Step: 24ms | Tot: 11s144ms | Loss: 2.752 | Acc: 67.760% (6776/10000) 79/79 \n","\n","Epoch: 85\n"," [================================================================>]  Step: 295ms | Tot: 3m4s | Loss: 0.036 | Acc: 98.716% (49358/50000) 391/391 \n"," [================================================================>]  Step: 23ms | Tot: 11s146ms | Loss: 2.371 | Acc: 69.310% (6931/10000) 79/79 \n","\n","Epoch: 86\n"," [================================================================>]  Step: 297ms | Tot: 3m3s | Loss: 0.041 | Acc: 98.500% (49250/50000) 391/391 \n"," [================================================================>]  Step: 24ms | Tot: 11s107ms | Loss: 1.613 | Acc: 77.200% (7720/10000) 79/79 \n","\n","Epoch: 87\n"," [================================================================>]  Step: 297ms | Tot: 3m3s | Loss: 0.033 | Acc: 98.824% (49412/50000) 391/391 \n"," [================================================================>]  Step: 25ms | Tot: 11s84ms | Loss: 1.992 | Acc: 73.630% (7363/10000) 79/79 \n","\n","Epoch: 88\n"," [================================================================>]  Step: 296ms | Tot: 3m4s | Loss: 0.034 | Acc: 98.800% (49400/50000) 391/391 \n"," [================================================================>]  Step: 24ms | Tot: 11s102ms | Loss: 2.516 | Acc: 71.060% (7106/10000) 79/79 \n","\n","Epoch: 89\n"," [================================================================>]  Step: 297ms | Tot: 3m5s | Loss: 0.036 | Acc: 98.704% (49352/50000) 391/391 \n"," [================================================================>]  Step: 24ms | Tot: 11s149ms | Loss: 1.505 | Acc: 77.020% (7702/10000) 79/79 \n","\n","Epoch: 90\n"," [================================================================>]  Step: 296ms | Tot: 3m4s | Loss: 0.037 | Acc: 98.684% (49342/50000) 391/391 \n"," [================================================================>]  Step: 23ms | Tot: 11s137ms | Loss: 1.381 | Acc: 78.730% (7873/10000) 79/79 \n","\n","Epoch: 91\n"," [================================================================>]  Step: 303ms | Tot: 3m4s | Loss: 0.028 | Acc: 99.046% (49523/50000) 391/391 \n"," [================================================================>]  Step: 25ms | Tot: 11s142ms | Loss: 1.301 | Acc: 81.160% (8116/10000) 79/79 \n","\n","Epoch: 92\n"," [================================================================>]  Step: 298ms | Tot: 3m4s | Loss: 0.036 | Acc: 98.756% (49378/50000) 391/391 \n"," [================================================================>]  Step: 25ms | Tot: 11s155ms | Loss: 2.812 | Acc: 64.410% (6441/10000) 79/79 \n","\n","Epoch: 93\n"," [================================================================>]  Step: 302ms | Tot: 3m5s | Loss: 0.034 | Acc: 98.848% (49424/50000) 391/391 \n"," [================================================================>]  Step: 25ms | Tot: 11s116ms | Loss: 2.177 | Acc: 70.570% (7057/10000) 79/79 \n","\n","Epoch: 94\n"," [================================================================>]  Step: 296ms | Tot: 3m5s | Loss: 0.030 | Acc: 98.980% (49490/50000) 391/391 \n"," [================================================================>]  Step: 24ms | Tot: 11s86ms | Loss: 1.780 | Acc: 75.580% (7558/10000) 79/79 \n","\n","Epoch: 95\n"," [================================================================>]  Step: 294ms | Tot: 3m5s | Loss: 0.035 | Acc: 98.760% (49380/50000) 391/391 \n"," [================================================================>]  Step: 23ms | Tot: 11s161ms | Loss: 2.007 | Acc: 74.870% (7487/10000) 79/79 \n","\n","Epoch: 96\n"," [================================================================>]  Step: 296ms | Tot: 3m5s | Loss: 0.030 | Acc: 98.952% (49476/50000) 391/391 \n"," [================================================================>]  Step: 24ms | Tot: 11s164ms | Loss: 4.043 | Acc: 60.420% (6042/10000) 79/79 \n","\n","Epoch: 97\n"," [================================================================>]  Step: 297ms | Tot: 3m4s | Loss: 0.032 | Acc: 98.882% (49441/50000) 391/391 \n"," [================================================================>]  Step: 25ms | Tot: 11s184ms | Loss: 1.312 | Acc: 80.100% (8010/10000) 79/79 \n","\n","Epoch: 98\n"," [================================================================>]  Step: 298ms | Tot: 3m5s | Loss: 0.028 | Acc: 99.040% (49520/50000) 391/391 \n"," [================================================================>]  Step: 27ms | Tot: 11s97ms | Loss: 2.111 | Acc: 73.990% (7399/10000) 79/79 \n","\n","Epoch: 99\n"," [================================================================>]  Step: 297ms | Tot: 3m6s | Loss: 0.034 | Acc: 98.814% (49407/50000) 391/391 \n"," [================================================================>]  Step: 26ms | Tot: 11s96ms | Loss: 1.426 | Acc: 80.930% (8093/10000) 79/79 \n","Best Accuracy:  85.44\n"],"name":"stdout"}]}]}